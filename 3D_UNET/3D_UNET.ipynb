{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv3D, UpSampling2D, MaxPool3D, Conv3DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization, Add, Reshape\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.backend import squeeze, transpose, reshape\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 64 # Input feature width/height\n",
    "INPUT_DEPTH = 64 # Input depth \n",
    "INPUT_CHANNEL = 1\n",
    "OUTPUT_SIZE = 64 # Output feature width/height \n",
    "OUTPUT_DEPTH = 64 # Output depth\n",
    "OUTPUT_CHANNEL = 1\n",
    "OUTPUT_CLASSES = 4 # Number of output classes in dataset\n",
    "\n",
    "base_filt = 32\n",
    "dropout_rate = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_batch_relu(tensor, filters, name, kernel = [3,3,3], stride = [1,1,1]):\n",
    "    conv = Conv3D(filters, kernel_size = kernel, strides = stride, padding = 'same',\n",
    "                  kernel_initializer = tf.keras.initializers.TruncatedNormal(stddev=0.1), \n",
    "                  kernel_regularizer = tf.keras.regularizers.l2(0.1), \n",
    "                  name=name)(tensor)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    return conv\n",
    "\n",
    "def upconvolve(tensor, filters, name, kernel = 2, stride = 2, activation = None):\n",
    "    conv = Conv3DTranspose(filters, kernel_size = kernel, strides = stride, padding = 'same', use_bias=False, \n",
    "                                      kernel_initializer = tf.keras.initializers.TruncatedNormal,  \n",
    "                                      kernel_regularizer = tf.keras.regularizers.l2(0.1), name=name)(tensor)\n",
    "    return conv\n",
    "\n",
    "def centre_crop_and_concat(prev_conv, up_conv):\n",
    "    # Needed if the padding is 'valid'\n",
    "    p_c_s = prev_conv.get_shape()\n",
    "    u_c_s = up_conv.get_shape()\n",
    "    offsets =  np.array([0, (p_c_s[1] - u_c_s[1]) // 2, (p_c_s[2] - u_c_s[2]) // 2, \n",
    "                         (p_c_s[3] - u_c_s[3]) // 2, 0], dtype = np.int32)\n",
    "    size = np.array([-1, u_c_s[1], u_c_s[2], u_c_s[3], p_c_s[4]], np.int32)\n",
    "    prev_conv_crop = tf.slice(prev_conv, offsets, size)\n",
    "    up_concat = tf.concat((prev_conv_crop, up_conv), 4)\n",
    "    return up_concat\n",
    "\n",
    "\n",
    "model_input = Input(shape=(INPUT_DEPTH, INPUT_SIZE, INPUT_SIZE, INPUT_CHANNEL), name='input_img')\n",
    "# Level zero\n",
    "conv_0_1 = conv_batch_relu(model_input, base_filt, name='conv_0_1')\n",
    "conv_0_2 = conv_batch_relu(conv_0_1, base_filt*2, name='conv_0_2')\n",
    "# Level one\n",
    "max_1_1 = MaxPool3D([2,2,2], [2,2,2], name='max_1_1')(conv_0_2) \n",
    "conv_1_1 = conv_batch_relu(max_1_1, base_filt*2, name='conv_1_1')\n",
    "conv_1_2 = conv_batch_relu(conv_1_1, base_filt*4, name='conv_1_2')\n",
    "conv_1_2 = Dropout(rate = dropout_rate, name='conv_1_2_dropout')(conv_1_2)\n",
    "# Level two\n",
    "max_2_1 = MaxPool3D([2,2,2], [2,2,2], name='max_2_1')(conv_1_2) \n",
    "conv_2_1 = conv_batch_relu(max_2_1, base_filt*4, name='conv_2_1')\n",
    "conv_2_2 = conv_batch_relu(conv_2_1, base_filt*8, name='conv_2_2')\n",
    "conv_2_2 = Dropout(rate = dropout_rate, name='conv_2_2_dropout')(conv_2_2)\n",
    "# Level three\n",
    "max_3_1 = MaxPool3D([2,2,2], [2,2,2], name='max_3_1')(conv_2_2) \n",
    "conv_3_1 = conv_batch_relu(max_3_1, base_filt*8, name='conv_3_1')\n",
    "conv_3_2 = conv_batch_relu(conv_3_1, base_filt*16, name='conv_3_2')\n",
    "conv_3_2 = Dropout(rate = dropout_rate, name='conv_3_2_dropout')(conv_3_2)\n",
    "# Level two\n",
    "up_conv_3_2 = upconvolve(conv_3_2, base_filt*16, kernel = 2, stride = [2,2,2], name='up_conv_3_2')  \n",
    "concat_2_1 = centre_crop_and_concat(conv_2_2, up_conv_3_2)\n",
    "conv_2_3 = conv_batch_relu(concat_2_1, base_filt*8, name='conv_2_3')\n",
    "conv_2_4 = conv_batch_relu(conv_2_3, base_filt*8, name='conv_2_4')\n",
    "conv_2_4 = Dropout(rate = dropout_rate, name='conv_2_4_dropout')(conv_2_4)\n",
    "# Level one\n",
    "up_conv_2_1 = upconvolve(conv_2_4, base_filt*8, kernel = 2, stride = [2,2,2], name='up_conv_2_1')\n",
    "concat_1_1 = centre_crop_and_concat(conv_1_2, up_conv_2_1)\n",
    "conv_1_3 = conv_batch_relu(concat_1_1, base_filt*4, name='conv_1_3')\n",
    "conv_1_4 = conv_batch_relu(conv_1_3, base_filt*4, name='conv_1_4')\n",
    "conv_1_4 = Dropout(rate = dropout_rate, name='conv_1_4_dropout')(conv_1_4)\n",
    "# Level zero\n",
    "up_conv_1_0 = upconvolve(conv_1_4, base_filt*4, kernel = 2, stride = [2,2,2], name='conv_1_0') \n",
    "concat_0_1 = centre_crop_and_concat(conv_0_2, up_conv_1_0)\n",
    "conv_0_3 = conv_batch_relu(concat_0_1, base_filt*2, name='conv_0_3')\n",
    "conv_0_4 = conv_batch_relu(conv_0_3, base_filt*2, name='conv_0_4')\n",
    "conv_0_4 = Dropout(rate = dropout_rate, name='conv_0_4_dropout')(conv_0_4)\n",
    "conv_out = Conv3D(OUTPUT_CLASSES, [1,1,1], [1,1,1], padding = 'same', name='conv_out')(conv_0_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet3d = Model(inputs=model_input, outputs=conv_out, name='unet3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"unet3d\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_img (InputLayer)          [(None, 64, 64, 64,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0_1 (Conv3D)               (None, 64, 64, 64, 3 896         input_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 64, 3 128         conv_0_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 64, 3 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv_0_2 (Conv3D)               (None, 64, 64, 64, 6 55360       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 64, 6 256         conv_0_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 64, 6 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_1_1 (MaxPooling3D)          (None, 32, 32, 32, 6 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_1 (Conv3D)               (None, 32, 32, 32, 6 110656      max_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 32, 6 256         conv_1_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 32, 6 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_2 (Conv3D)               (None, 32, 32, 32, 1 221312      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 32, 1 512         conv_1_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 32, 1 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_2_dropout (Dropout)      (None, 32, 32, 32, 1 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_2_1 (MaxPooling3D)          (None, 16, 16, 16, 1 0           conv_1_2_dropout[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_1 (Conv3D)               (None, 16, 16, 16, 1 442496      max_2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 16, 1 512         conv_2_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 16, 1 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_2 (Conv3D)               (None, 16, 16, 16, 2 884992      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 16, 2 1024        conv_2_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 16, 2 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_2_dropout (Dropout)      (None, 16, 16, 16, 2 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_3_1 (MaxPooling3D)          (None, 8, 8, 8, 256) 0           conv_2_2_dropout[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_1 (Conv3D)               (None, 8, 8, 8, 256) 1769728     max_3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 8, 256) 1024        conv_3_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 8, 256) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_2 (Conv3D)               (None, 8, 8, 8, 512) 3539456     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 8, 512) 2048        conv_3_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 8, 512) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_2_dropout (Dropout)      (None, 8, 8, 8, 512) 0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Slice (TensorFlowOp [(None, 16, 16, 16,  0           conv_2_2_dropout[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_conv_3_2 (Conv3DTranspose)   (None, 16, 16, 16, 5 2097152     conv_3_2_dropout[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 16, 16, 16,  0           tf_op_layer_Slice[0][0]          \n",
      "                                                                 up_conv_3_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_3 (Conv3D)               (None, 16, 16, 16, 2 5308672     tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 16, 2 1024        conv_2_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 16, 2 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_4 (Conv3D)               (None, 16, 16, 16, 2 1769728     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 16, 2 1024        conv_2_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 16, 2 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_4_dropout (Dropout)      (None, 16, 16, 16, 2 0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Slice_1 (TensorFlow [(None, 32, 32, 32,  0           conv_1_2_dropout[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_conv_2_1 (Conv3DTranspose)   (None, 32, 32, 32, 2 524288      conv_2_4_dropout[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 32, 32, 32,  0           tf_op_layer_Slice_1[0][0]        \n",
      "                                                                 up_conv_2_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_3 (Conv3D)               (None, 32, 32, 32, 1 1327232     tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 32, 1 512         conv_1_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 32, 1 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_4 (Conv3D)               (None, 32, 32, 32, 1 442496      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 32, 1 512         conv_1_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 32, 1 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_4_dropout (Dropout)      (None, 32, 32, 32, 1 0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Slice_2 (TensorFlow [(None, 64, 64, 64,  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_0 (Conv3DTranspose)      (None, 64, 64, 64, 1 131072      conv_1_4_dropout[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_2 (TensorFlo [(None, 64, 64, 64,  0           tf_op_layer_Slice_2[0][0]        \n",
      "                                                                 conv_1_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_0_3 (Conv3D)               (None, 64, 64, 64, 6 331840      tf_op_layer_concat_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 64, 6 256         conv_0_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 64, 6 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_0_4 (Conv3D)               (None, 64, 64, 64, 6 110656      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 64, 6 256         conv_0_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 64, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_0_4_dropout (Dropout)      (None, 64, 64, 64, 6 0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_out (Conv3D)               (None, 64, 64, 64, 4 260         conv_0_4_dropout[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 19,077,636\n",
      "Trainable params: 19,072,964\n",
      "Non-trainable params: 4,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet3d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def soft_max_loss(model_labels, conv_out, num_classes=OUTPUT_CLASSES, loss_weights=[1, 150, 100, 1.0], do_weight=True):\n",
    "    model_labels = tf.image.convert_image_dtype(model_labels, tf.int32)\n",
    "    conv_out = tf.image.convert_image_dtype(conv_out, tf.float32)\n",
    "    labels_one_hot = tf.squeeze(tf.one_hot(model_labels, num_classes, axis = -1), axis = -2)\n",
    "    labels_one_hot = tf.cast(labels_one_hot, tf.float32)\n",
    "    ce_loss = tf.nn.softmax_cross_entropy_with_logits(logits=conv_out, labels=labels_one_hot)\n",
    "    if do_weight:\n",
    "        weighted_loss = tf.reshape(tf.constant(loss_weights), [1, 1, num_classes]) # Format to the right size\n",
    "        weighted_one_hot = tf.reduce_sum(weighted_loss*labels_one_hot, axis = -1)\n",
    "        ce_loss = ce_loss * weighted_one_hot\n",
    "    loss = tf.reduce_mean(ce_loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "unet3d.compile(op, \n",
    "               loss= soft_max_loss, \n",
    "               metrics=['accuracy'],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint\n",
    "checkpoint_path = \"./checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = ModelCheckpoint(checkpoint_path,\n",
    "                              monitor = 'val_loss',\n",
    "                              verbose = 1,\n",
    "                              save_best_only=False,\n",
    "                              save_weights_only=False,\n",
    "                              period=10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = unet3d.fit(x=X_train, \n",
    "                y=Y_train, \n",
    "                batch_size=3,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                validation_split = 0.2,\n",
    "                #validation_data=(X_test, X_test)\n",
    "                callbacks = [cp_callback]\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
